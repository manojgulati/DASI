Machine Learning By Prof. Pedro Domingos (UW) {Courseera}
Notes: Manoj Gulati PhD EE IIIT-Delhi (India)

Week-1
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Key Elements of ML

Three components of all ML algorithms:
1). Representation
	- Decision Trees
	- Sets of rules/logic programs
	- Instances
	- Graphical Models (bayesian nets/ markov nets)
	- Neural Networks 
		(Idea here is to reverse engineer the computation: tries to mimic multiple neurons working inside human brain)
	- Support vector machines (relatively new techinique)
	- Model ensembles (best thing in learning is to use fusion of several techniques/models: similar to wisdom of crowds)
2). Evaluation (in order to inspect whether the results that you expected have been achieved i.e. gauge the outputs)
	- Accuracy
	- Precision and recall
		(precision is what fraction of your predicted spams were really spam and recall is out of all that were really spam how many have you correctly identified as spam)
	- Squared error (used where numeric computations are involved espcially like predicting error in numeric quantities)
	- Likelihood (how likely is what you are saying acc. to your model. It might not be useful to generalize results)
	- Posterior probability (prior probability + likelihood = posterior probability that can be used to evaluate your model)
	- Cost/utility (sometimes cost of false positive is much more than false negative and this has to be accounted e.g. putting an imp. mail in to spam)
	- Margin (used to infer how far you are from actual results e.g. used in SVMs)
	- Entropy
	- KL divergence
3). Optimisation (in order to generate possible candidates and select one to handover it to user. It requires some smart strategy to evaluate and pick the best one. People in operations research and continous maths try to use this) {Type of optimisation depends on type of representation and evaluation metric you choose.}
	- Combinatorial optimisation (for discrete representations)	
		e.g. greedy search
	- Convex optimisation (to optimise numerical paramters usually continous)
		e.g. gradient descent
	- Constrained optimisation (combination of continous and combinatorial optimisation but constraints have to be linear or have to be converted in to linear)
		e.g. Linear programming


------------------------------------------------------------------------
Types of Learning

1). Supervised (inductive) learning (easy)
	- training data includes the desired outputs
2). Unsupervised learning (hard)
	- training data doesn't include the desired outputs
3). Semi-supervised learning (harder)
	- training data includes a few of the desired outputs
4). Reinforcement learning (hardest)
	- rewards from sequence of actions

Inductive learning
	- Given fn. (x,f(x)) predict f(x) for new examples of x.
	- Discrete : classification
	- Continous : regression
	- f(x) = probability(x): probability estimation

Supervised learning
	- Decision tree induction
	- Rule induction
	- Instance based learning
	- Bayesian learning
	- Neural networks
	- Support vector machines
	- Model ensembles
	- Learning theory (to cover overfitting and curse of dimensionality)
Unsupervised learning
	- Clustering
	- Dimensionality reduction (use in order to analyse or visualize >=100k dimensions)

------------------------------------------------------------------------
Application areas of Supervised learning
	- Situations where there is no Human expert
	- Situations where human can perform the task but can't explain how they did it
	- Situations where the desired function is changing quite frequently
	- Situations where each user needs a customized function

Learning a boolean fn.
	- Given are four known inputs
	- Try to figure out the unknown boolean fn. with known function examples
	- Soln: Classification, nearest neighbor, if-else statments (maximally overfitting case)
	- Goal of machine learning is to provide soln. to unknown examples as well (future inputs)
	- Most of the real world problems will have double exponential complexity and won't be feasible to crack
	 in brute force way. Ideally we need to generalize the soln.
	- One way is Hypothesis spaces
		-> m-of-n rules: where you select the set of cases and figure out base problem. This is widely used in medical data analytics where either a is true or b is true or both are true. More cases are added if information is not giving apt. diagnosis.

Two views of learning
	- Learning is the removal of our remaining uncertainity.
	- Learning requires guessing a good, small hypothesis class.
Machine learning involves guessing but that means it requires lot of instinct, gut and domain knowledge to make an informed guess. It doesn't mean we should start in a hit and try way with all the possible algo's available.

We could be wrong !!
	- Our prior knowledge might be wrong. In the sense that new inputs may lead to prove that previously acquired knowledge was wrong.
	- Our guess of hypothesis class could be wrong. i.e. new inputs may change to belief and show that previous classification or guess was wrong.

Two strategies for machine learning
	- Develop languages for expressing prior knowledge (rule grammars)
	- Develop flexible hypothesis spaces (nested collection of hypothesis, decision trees, neural networks)
	- Goal is to develop algorithms for finding an hypothesis that fits the data

------------------------------------------------------------------------
Terminology
	- Training example: <x, f(x)> i.e. sample 
	- Target function (target concept): true fn. f that we are trying to learn
	- Hypothesis: proposed fn. h similar to f
	- Concept: a boolean fn. f(x)=1 is a positive examples.
	- Classifier: a discrete valued fn. f(x) belongs to {1,....,K}. Classifier is the end product of learning and it can be used to predict classes in future w/o using training samples.
	- Hypothesis space: a space of all possible hypothesis that can be output of the learning algorithm.
	- Version space: subset of hypothesis space that have not been yet ruled out. So at some point of time version space may lead to zero. 
	- Batch learning: Learning the model/classifier on historical data.
	- Online learning: Learning the model in real time mode or the model gets updated as more and more data is pumped in.

Framework (dimensions) for Hypothesis Spaces
	- Size: fixed or variable size of hypothesis spaces
	- Randomness: deterministic or stochastic hypothesis spaces
	- Parameterization: symbolic (discrete) or continous hypothesis spaces

Framework (dimensions) for Learning Algorithms (these dimensions have to be taken care of based upon your application area)
	- Search Procedure
		- Direct computation: search for hypothesis e.g. naive bayesian
		- Local search: start with some initial hypothesis and than optimize locally e.g. neural nets
		- Constructive search: start with empty hypothesis, gradually add structure/beliefs with incremental occurances of training samples e.g. decision trees
	- Timings
		- Eager
		- Lazy
	- Online Vs. Batch (for eager algorithms)
		- Online
		- Batch
		Whenever problem is not changing we can use 'batch' based learning. Also it is more effective as you have hold of all the training data but in 'online' training you have to adapt your model quickly on basis of real time feed of data. Both have there on application areas and use cases.

Difference b/w AI, ML and Data mining (DM)
	- ML is a sub-field of AI 
	- ML and data mining are quite related but certain topics reinforcement learning that are not covered in DM. Also certain techniques like visualization and databases that are covered in DM but not in ML.

Week-2
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Decision Trees (DT)
	- simple (not hard to use and output is easy to interpret)
	- scalable
	- Variable size
	- Deterministic
	- Discrete and continous parameters
	* All the above listed features make DT's a nice algorithm

Learning algorithms for DT's can be described as: 
	- Constructive search: tree is built gradually by adding nodes
	- Eager
	- Batch

Decision Trees (DT) hypothesis space
	- Internal nodes test the valueof particular x_j and branch according to results.
	- Leaf nodes specify the class h(x)
	- Selecting starting node/features is most imp. for any DT to work. In some cases you may end up in choosing a wrong feature which may lead to exponentially smaller number of trial cases and may end up in non-optimal DT.
	- If features in DT are continous, internal nodes may test the feature against a threshold. This means in practice in certain cases you can't approximate using DT's. High dimensional data may be hard fit using DT's.

Decision tree decision boundaries
	- x1>3, x2<4, x1<2, x2>5 may help in deciding axis decision boundaries.
	- We can DT out of any truth table. However in worst case DT will have all the cases of truth table covered in leaf nodes.
	- DT may require exponential number of nodes in worst scenarios.
	- as the number of nodes in tree increases, the hypothesis space also increases (depth1, depth2, etc).
	- First step in forming a DT is selecting a 'root' node but the attribute with highest weight must be made root. You can also choose the root node to divide training cases in to half. 
	- Best selection for 'root' node would be to choose an attribute which clearly diversifies b/w two categories.
	- Finding an appropriate attribute for finding smallest decision tree is an NP complete problem. It has to be governed by some heuristics. But those heuristics must lead to min. error rate.

A better heuristic from information theory (covering information gain or mutual information)
	- Bernouli distribution: binary solution (either one or two)
	- Amount of information gained will be higher when uncertainity of the event is higher. Less the likelihood higher is the surprise level.
	- Degree of surprise: -log P(V=v) where P is probability of occurance of V=v.
	- Entropy: average of surprise 
		i.e. H(V) = Sum from v=0 to 1( -P(H=v)logP(H=v) )	Here it is multiplied by probability to consider average. Things which occur often have higher probability.
	- Entropy is a measure of uncertainty.
	- Mutual information: between two variables is the reduction in entropy of one by knowing the class of other variable. 
		i.e. 



